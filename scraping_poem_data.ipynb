{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "if(not sys.version_info[0]<3):\n",
    "    from importlib import reload \n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will scrape the english haikus from the website being requested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('http://www.tempslibres.org/tl/tlphp/dbauteursl.php?lang=en&lg=e') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(soup.prettify())\n",
    "#list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#id=\"content\" and class='liensurl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('td',class_='liensurl')\n",
    "soup.find_all('tr')\n",
    "print(len(soup.select('tr td.liensdesc'))) #[name, location, number of poems in database]\n",
    "len(soup.select('tr td.liensurl'))#This gives the number of poets as it contains the url to their poems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_poets=len(soup.select('tr td.liensurl'))\n",
    "poets=np.array([[soup.select('tr td.liensdesc')[i*3].get_text(),soup.select('tr td.liensdesc')[i*3+1].get_text(),'http://www.tempslibres.org/tl/tlphp/dbhk01.php?auteur='+soup.select('tr td.liensurl')[i].get_text()+'&lg=e'] for i in range(num_poets)])\n",
    "#page is http://www.tempslibres.org/tl/tlphp/dbhk01.php?auteur=(****NAME****)&lg=e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Odd G. Aksnes ', 'Toensberg - Norway',\n",
       "        'http://www.tempslibres.org/tl/tlphp/dbhk01.php?auteur=aksn-o &lg=e'],\n",
       "       ['Melanie Alberts ', 'Austin, Texas - USA',\n",
       "        'http://www.tempslibres.org/tl/tlphp/dbhk01.php?auteur=albe-m &lg=e'],\n",
       "       ['Mohamad Alsari ', 'Alep - Syria',\n",
       "        'http://www.tempslibres.org/tl/tlphp/dbhk01.php?auteur=alsa-m &lg=e']],\n",
       "      dtype='<U67')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poets[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following gets the poems from the website. It works ok when the poems are in english. Not otherwise, this is because it is a french website that offers traductions in the same html element. The traductions can something be given *before* the non-translated version. Kind of annoying.\n",
    "\n",
    "The url has a lg=e at the end, i.e. I'm supposed to only have the poems that are in English, but their database ain't no bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findpoems(url):\n",
    "    page=requests.get(url)\n",
    "    poempage=BeautifulSoup(page.content,'html.parser').select('p.haiku')\n",
    "    npoem=len(poempage)\n",
    "    poems=[]\n",
    "    for i in range(npoem):\n",
    "        tmp=poempage[i].get_text()\n",
    "        a=0\n",
    "        for _ in range(3):\n",
    "            a+=tmp[a:].find('\\n')+2 #look for the third \\n, this characterizes the end of a haiku.\n",
    "        poems.append(tmp[:a].replace('\\n',' \\n '))\n",
    "    return np.array(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alep - Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Avec la vieille balançoire \\n les souvenirs  \\n vi',\n",
       "       'ساعة بلا عقارب\\r \\n على نافذتك المهجورة \\r \\n ال',\n",
       "       'horloge sans aiguilles \\n sur ta fenêtre abandonnée \\n la',\n",
       "       'Maison abandonnée\\r \\n de la fenêtre cassée\\r \\n la',\n",
       "       'بعد إطفاء الأضواء\\r \\n على واجهة متجر الأسلحة\\r \\n ال',\n",
       "       \"les lampes éteintes \\n sur la vitrine d'armes \\n la\",\n",
       "       \"Deux ailes d'oiseau \\n ton rouge à lèvres \\n su\",\n",
       "       'خارجاً من البئر\\r \\n بالدلو أصطاد\\r \\n ال',\n",
       "       \"du puits \\n dans un seau j'attrape \\n une lune \\n  \\n \",\n",
       "       'إشارة ربط الحزام \\r \\n كل ماتبقى \\r \\n عل'],\n",
       "      dtype='<U73')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(poets[2,1])\n",
    "findpoems(poets[2,2])[:10] #Example of a non-english poet - From Syria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central Oregon - USA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['mountain cave -- \\n from out of darkness \\n the morning light \\n  \\n ',\n",
       "       \"after its first flight \\n the young gerfalcon's talons \\n tighter on my glove \\n  \\n \"],\n",
       "      dtype='<U81')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(poets[7,1])\n",
    "findpoems(poets[7,2])[:10] #poet from the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poets_USA=np.array([p for p in poets if 'USA' in p[1]])#I'll hope the authors of Murica all write in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.26 s, sys: 256 ms, total: 7.51 s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def createdatabase(poets,fp='peom_data.txt'):\n",
    "    if(os.path.exists(fp)):\n",
    "        os.remove(fp)\n",
    "        f=open(fp,'w')\n",
    "    else:\n",
    "        f=open(fp,'w')\n",
    "        \n",
    "        #the above code deletes and recreate the file\n",
    "        #we do this as the code belows just appends to it.\n",
    "        #Without the above, running this function twice would add copies of the database.\n",
    "        \n",
    "    for i in range(len(poets)):\n",
    "        poems=findpoems(poets[i,2])\n",
    "        json_file={'Name': poets[i,0], 'Location': poets[i,1], 'Poems': poems.tolist()}\n",
    "        json.dump(json_file,f,separators=(',',':'))\n",
    "    f.close()\n",
    "    return\n",
    "def createdatabase_nponly(poets,fp='peom_data.txt'):\n",
    "    poems=[]\n",
    "    for i in range(len(poets)):\n",
    "        poems=np.concatenate((poems,findpoems(poets[i,2])))\n",
    "    np.save('poem_npdata',np.array(poems))\n",
    "    return\n",
    "%time createdatabase_nponly(poets_USA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have some sort of database of haikus. I uploaded the output of this function in Google Drive. It is under the name poem_data.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poems_list=np.load('poem_npdata.npy')\n",
    "npoem=len(poems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5308"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic=set(nltk.word_tokenize(poems_list[0]))\n",
    "for i in range(npoem):\n",
    "    dic= dic | set(nltk.word_tokenize(poems_list[i]))\n",
    "len(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Either build an embedding from this or use other already embedded dictionary. I'll try an outside one.\n",
    "2) Feed the Poems into an LSTM I guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
